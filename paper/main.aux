\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{ren2017faster}
\citation{gupta2019lvis}
\@writefile{toc}{\contentsline {section}{\numberline {1}引言与背景 (Introduction \& Background)}{1}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}研究背景与动机}{1}{subsection.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.1.1}传统目标检测的成功与局限}{1}{subsubsection.1.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.1.2}现实世界的长尾分布与标注瓶颈}{1}{subsubsection.1.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.1.3}实际应用场景的迫切需求}{2}{subsubsection.1.1.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces 封闭集检测与开放集检测的对比}}{2}{figure.1}\protected@file@percent }
\newlabel{fig:p3}{{1}{2}{封闭集检测与开放集检测的对比}{figure.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}范式转移：视觉-语言融合的突破}{2}{subsection.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.1}从离散 ID 到语义嵌入}{2}{subsubsection.1.2.1}\protected@file@percent }
\citation{radford2021learning}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces 传统分类器与开放检测器的对比}}{3}{table.1}\protected@file@percent }
\newlabel{tab:classifier_compare}{{1}{3}{传统分类器与开放检测器的对比}{table.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.2}CLIP：视觉-语言对齐的基石}{3}{subsubsection.1.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.3}区域-文本对齐的技术路径}{3}{subsubsection.1.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}核心概念界定与研究范围}{4}{subsection.1.3}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces 开放目标检测相关研究方向对比}}{4}{table.2}\protected@file@percent }
\newlabel{tab:research_direction}{{2}{4}{开放目标检测相关研究方向对比}{table.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.3.1}开放词汇目标检测 (OVD)}{4}{subsubsection.1.3.1}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces OVD 典型数据集}}{5}{table.3}\protected@file@percent }
\newlabel{tab:ovd_dataset}{{3}{5}{OVD 典型数据集}{table.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.3.2}传统开放世界目标检测 (OWOD)}{5}{subsubsection.1.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.3.3}基于OVD的开放世界检测:OVD+OWOD新范式}{6}{subsubsection.1.3.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces 基于 OVD 的开放世界检测统一框架}}{6}{figure.2}\protected@file@percent }
\newlabel{fig:p4}{{2}{6}{基于 OVD 的开放世界检测统一框架}{figure.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces 不同OWOD方法性能对比}}{6}{table.4}\protected@file@percent }
\newlabel{tab:owod_performance}{{4}{6}{不同OWOD方法性能对比}{table.4}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.3.4}OVD与开放世界检测的对比与联系}{7}{subsubsection.1.3.4}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {5}{\ignorespaces OVD、传统OWOD与基于OVD的开放世界检测对比}}{7}{table.5}\protected@file@percent }
\newlabel{tab:ovd_owod_compare}{{5}{7}{OVD、传统OWOD与基于OVD的开放世界检测对比}{table.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4}总结：技术演进路线图}{7}{subsection.1.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces 开放目标检测技术演进路线图}}{7}{figure.3}\protected@file@percent }
\newlabel{fig:p5}{{3}{7}{开放目标检测技术演进路线图}{figure.3}{}}
\@writefile{lot}{\contentsline {table}{\numberline {6}{\ignorespaces 开放目标检测技术演进阶段总结}}{8}{table.6}\protected@file@percent }
\newlabel{tab:tech_evolution}{{6}{8}{开放目标检测技术演进阶段总结}{table.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2}OVD 核心技术范式——从深度融合到实时推理}{8}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}高精度 OVD 框架：基于 Transformer 的多阶段深度对齐}{8}{subsection.2.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces 基于 Transformer 的高精度 OVD 框架整体架构与三阶段对齐流}}{9}{figure.4}\protected@file@percent }
\newlabel{fig:p1}{{4}{9}{基于 Transformer 的高精度 OVD 框架整体架构与三阶段对齐流}{figure.4}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.1}跨模态特征增强器}{9}{subsubsection.2.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.2}语言引导的查询选择}{10}{subsubsection.2.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.3}跨模态解码器与子句级去噪}{11}{subsubsection.2.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.4}分类与定位的对齐损失}{12}{subsubsection.2.1.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}实时化 OVD 框架：重参数化带来的感知革命}{12}{subsection.2.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces 实时化 OVD 框架整体架构}}{13}{figure.5}\protected@file@percent }
\newlabel{fig:p2}{{5}{13}{实时化 OVD 框架整体架构}{figure.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces 不同 OVD 检测框架的对比}}{13}{figure.6}\protected@file@percent }
\newlabel{fig:detection_framework}{{6}{13}{不同 OVD 检测框架的对比}{figure.6}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.1}RepVL-PAN 与视觉-语义交互}{13}{subsubsection.2.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.2}"先提示，后检测"：推理效率的质变}{14}{subsubsection.2.2.2}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {7}{\ignorespaces 重参数化前后的推理效率对比}}{15}{table.7}\protected@file@percent }
\newlabel{tab:reparam_efficiency}{{7}{15}{重参数化前后的推理效率对比}{table.7}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.3}区域-文本对比学习策略}{15}{subsubsection.2.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}两种技术范式的对比分析}{16}{subsection.2.3}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {8}{\ignorespaces 两种 OVD 技术范式的综合对比}}{17}{table.8}\protected@file@percent }
\newlabel{tab:ovd_paradigm_compare}{{8}{17}{两种 OVD 技术范式的综合对比}{table.8}{}}
\citation{owovd2025}
\@writefile{toc}{\contentsline {section}{\numberline {3}迈向开放与统一：OVD 向 OWD 的进阶与探索（基于 YOLO-World 提出的 OVD 框架）}{18}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}OVD 与 OWD 的统一任务探索：OW-OVD}{18}{subsection.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.1}核心挑战与技术路线}{18}{subsubsection.3.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.2}视觉相似度属性选择（VSAS）方法}{18}{subsubsection.3.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.3}混合属性-不确定性融合（HAUF）方法}{18}{subsubsection.3.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.4}性能评估与实验验证}{19}{subsubsection.3.1.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.5}深入分析与讨论}{19}{subsubsection.3.1.5}\protected@file@percent }
\citation{yolouniow2024}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}高效的通用开放世界检测范式：YOLO-UniOW}{20}{subsection.3.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces YOLO-UniOW 高效通用开放世界目标检测流程}}{20}{figure.7}\protected@file@percent }
\newlabel{fig:yolouniow_pipeline}{{7}{20}{YOLO-UniOW 高效通用开放世界目标检测流程}{figure.7}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.1}设计理念：基于 YOLO-World 的统一框架}{20}{subsubsection.3.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.2}通配符学习机制}{21}{subsubsection.3.2.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces 通配符学习机制流程}}{21}{figure.8}\protected@file@percent }
\newlabel{fig:wildcard_learning}{{8}{21}{通配符学习机制流程}{figure.8}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.3}高效增量学习能力}{21}{subsubsection.3.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.4}实时性能与通用性}{21}{subsubsection.3.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.5}深入分析与讨论}{22}{subsubsection.3.2.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}两种统一范式的对比与总结}{23}{subsection.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.1}综合对比分析}{23}{subsubsection.3.3.1}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {9}{\ignorespaces OW-OVD 与 YOLO-UniOW 综合对比}}{24}{table.9}\protected@file@percent }
\newlabel{tab:owod_yolouniow_comprehensive}{{9}{24}{OW-OVD 与 YOLO-UniOW 综合对比}{table.9}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.2}技术路线的互补性}{24}{subsubsection.3.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.3}共同挑战与未来方向}{24}{subsubsection.3.3.3}\protected@file@percent }
\bibstyle{plain}
\bibcite{ren2017faster}{1}
\bibcite{gupta2019lvis}{2}
\bibcite{radford2021learning}{3}
\bibcite{owovd2025}{4}
\bibcite{yolouniow2024}{5}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.4}总结与展望}{25}{subsubsection.3.3.4}\protected@file@percent }
\gdef \@abspage@last{25}
